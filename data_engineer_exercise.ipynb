{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation criteria\n",
    "\n",
    "The goal of this assignment is to get a view on your hands-on \"data engineering\" skills.  \n",
    "At our company, our data scientists and engineers collaborate on projects.  \n",
    "Your main focus will be creating performant & robust data flows.  \n",
    "For a take-home-assignment, we cannot grant you access to our infrastructure.  \n",
    "The assignement below measures your proficiency in general programming, data science & engineering tasks using python.  \n",
    "Completion should not take more than half a day.\n",
    "\n",
    "**We expect you to be proficient in:**\n",
    " * SQL queries (Sybase IQ system)\n",
    " * ETL flows (In collaboration with existing teams)\n",
    " * General python to glue it all together\n",
    " * Python data science ecosystem (Pandas + SKlearn)\n",
    " \n",
    "**In this exercise we expect you to demonstrate your ability to / knowledge of:**\n",
    " * Building a data science runtime\n",
    " * PEP8 / Google python styleguide\n",
    " * Efficiently getting the job done\n",
    " * Choose meaningfull names for variables & functions\n",
    " * Writing maintainable code (yes, you might need to document some steps)\n",
    " * Help a data scientist present interactive results.\n",
    " * Offer predictions via REST api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting-up a data science workspace\n",
    "\n",
    "We allow you full freedom in setting up a data science runtime.  \n",
    "The main objective is having a runtime where you can run this notebook and the code you will develop.  \n",
    "You can choose for a local setup on your pc, or even a cloud setup if you're up for it.   \n",
    "\n",
    "**In your environment, you will need things for:**\n",
    " * https request\n",
    " * python3 (not python2 !!)\n",
    " * (geo)pandas\n",
    " * interactive maps (e.g. folium, altair, ...)\n",
    " * REST apis\n",
    " \n",
    "**Deliverables we expect**:\n",
    " * notebook with the completed assignment\n",
    " * list of packages for your runtime (e.g. yml or txt file)\n",
    " * evidence of a working API endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like you to put all your import statements here, together in 1 place.  \n",
    "Before submitting, please make sure you remove any unused imports :-)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your imports go here.  You get pandas for free.\n",
    "import pandas as pd\n",
    "import requests\n",
    "import unittest\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import json\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import threading\n",
    "import subprocess as sub\n",
    "from pandas import json_normalize, DataFrame\n",
    "from math import cos, sin, asin, sqrt, radians\n",
    "from joblib import load\n",
    "from pathlib import Path\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from pyproj import CRS\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data ingestion exercises\n",
    "\n",
    "## Getting store location data from an API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Obtain a pandas dataframe  \n",
    "**Hint:** You will need to normalise/flatten the json, because it contains multiple levels  \n",
    "**API call:** https://ecgplacesmw.colruytgroup.com/ecgplacesmw/v3/nl/places/filter/clp-places  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clp_places(url: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Retreive dataset at url, put it in a\n",
    "    dataframe\n",
    "    Parameters:\n",
    "    url: link to dataset\n",
    "    Returns:\n",
    "    a dataframe containing retreived dataset\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    return json_normalize(response.json())\n",
    "\n",
    "\n",
    "df_clp = get_clp_places(\"https://ecgplacesmw.colruytgroup.com/ecgplacesmw/v3/nl/places/filter/clp-places\")\n",
    "df_clp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I left placeSearchOpeningHours column unflattened because I assume we want a row per store, not a row per store-and-its-opening-times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality checks\n",
    "\n",
    "We would like you to add several checks on this data based on these constraints:  \n",
    " * records > 200\n",
    " * latitude between 49 and 52\n",
    " * longitude between 2 and 7\n",
    " \n",
    "We dont want you to create a full blown test suite here, we're just gonna use 'asserts' from unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "quality_check = unittest.TestCase('__init__')  # renaming varible for better readability\n",
    "\n",
    "# checking records > 200\n",
    "quality_check.assertTrue(len(df_clp) - 200 > 0, \"Dataframe is too small\")\n",
    "\n",
    "\n",
    "# normally I would isolate functions in a separate .py file, leaving it here for ease of reading\n",
    "def count_in_range(col_name: str,\n",
    "                   min_val: int,\n",
    "                   max_val: int) -> int:\n",
    "\n",
    "    \"\"\"\n",
    "    calculates number of values in col_name that fit within\n",
    "    [min_val: max_val] interval\n",
    "    Parameters:\n",
    "    col_name: name of column in df_clp\n",
    "    min_val: minimum range value\n",
    "    max_val: maximum range value\n",
    "    Returns:\n",
    "    number of rows in datafwame within range\n",
    "    \"\"\"\n",
    "    return (df_clp[col_name]\n",
    "            .astype(float)\n",
    "            .apply(lambda x: (x >= min_val) and (x <= max_val))\n",
    "            .sum())\n",
    "\n",
    "\n",
    "# checking that latitude is in correct range\n",
    "in_range_lat = count_in_range('geoCoordinates.latitude',\n",
    "                              49,\n",
    "                              52)\n",
    "quality_check.assertEqual(in_range_lat,\n",
    "                          len(df_clp),\n",
    "                          f'{len(df_clp)-in_range_lat} records outside range')\n",
    "\n",
    "# checking longitude is in correct range\n",
    "in_range_lon = count_in_range('geoCoordinates.longitude',\n",
    "                              2,\n",
    "                              7)\n",
    "quality_check.assertEqual(in_range_lon,\n",
    "                          len(df_clp),\n",
    "                          f'{len(df_clp)-in_range_lon} records outside range')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature creation\n",
    "\n",
    "Create a new column \"antwerpen\" which is 1 for all stores in Antwerpen (province) and 0 for all others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "# info about postal codes from\n",
    "# https://nl.wikipedia.org/wiki/Postnummers_in_Belgi%C3%AB#2000_-_2999_provincie_Antwerpen\n",
    "df_clp['antwerpen'] = (df_clp['address.postalcode']\n",
    "                       .astype(int)\n",
    "                       .apply(lambda x: 1 if x >= 2000 and x <= 2999 else 0))\n",
    "\n",
    "df_clp[\"antwerpen\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict used car value\n",
    "\n",
    "A datascientist in our team made a basic model to predict car prices.  \n",
    "The model was saved to disk ('lgbr_cars.model') using joblib's dump fuctionality.  \n",
    "Documentation states the model is a LightGBM Regressor, trained using the sk-learn api.  \n",
    "\n",
    "**As engineer, your task it to expose this model as REST-api.** \n",
    "\n",
    "First, retrieve the model via the function below.  \n",
    "Change the path according to your setup.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "def retrieve_model(path: str) -> LGBMRegressor:\n",
    "    \"\"\"\n",
    "    Loads model from specified path\n",
    "    Parameters:\n",
    "    path: path to model\n",
    "    Returns:\n",
    "    model object\n",
    "    \"\"\"\n",
    "    trained_model = load(path)\n",
    "    return trained_model\n",
    "\n",
    "\n",
    "lgbr_cars = retrieve_model(\"models/lgbr_cars.model\")\n",
    "\n",
    "quality_check.assertEqual(str(type(lgbr_cars)),\n",
    "                          \"<class 'lightgbm.sklearn.LGBMRegressor'>\",\n",
    "                          type(lgbr_cars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have your trained model, lets do a functional test based on the parameters below.  \n",
    "You have to present the parameters in this order.  \n",
    "\n",
    "* vehicleType: coupe\n",
    "* gearbox: manuell\n",
    "* powerPS: 190\n",
    "* model: NaN\n",
    "* kilometer: 125000\n",
    "* monthOfRegistration: 5 \n",
    "* fuelType: diesel\n",
    "* brand: audi\n",
    "\n",
    "Based on these parameters, you should get a predicted value of 14026.35068804\n",
    "However, the model doesnt accept string inputs, see the integer encoding below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_input = [[3, 1, 190, -1, 125000, 5, 3, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "\n",
    "def make_prediction(trained_model: LGBMRegressor, single_input: list) -> float:\n",
    "    \"\"\"\n",
    "    Produces model prediction for a single instance\n",
    "    Parameters:\n",
    "    trained_model: a trained model\n",
    "    single_input: an instance that needs to be predictred\n",
    "    Returns:\n",
    "    model prediction\n",
    "    \"\"\"\n",
    "    predicted_value = trained_model.predict(single_input)[0]\n",
    "    return predicted_value\n",
    "\n",
    "\n",
    "predicted_value = make_prediction(lgbr_cars, model_test_input)\n",
    "\n",
    "quality_check.assertAlmostEqual(predicted_value, 14026.35, places=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you got this model up and running, we want you to **expose it as a rest api.**  \n",
    "We don't expect you to set up any authentication.  \n",
    "We're not looking for beautiful inputs, just make it work.  \n",
    "**Building this endpoint should NOT be done in a notebook, but in proper .py file(s)**\n",
    "\n",
    "Once its up and running, use it to predict the following input:\n",
    "* [-1,1,0,118,150000,0,1,38] ==> prediction should be 13920.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_flask():\n",
    "    \"\"\"\n",
    "    Starts a flask app in a separate thread\n",
    "    to free up other notebook cells\n",
    "    \"\"\"\n",
    "    sub.call('flask run', shell=True)\n",
    "\n",
    "\n",
    "# start local flask server\n",
    "threading.Thread(target=start_flask).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "please wait for \"running at 127.0.0.1\" message before running next cell :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction for test instance\n",
    "response = requests.get('http://127.0.0.1:5000/predict',\n",
    "                        data=json.dumps({'instance': [-1, 1, 0, 118, 150000, 0, 1, 38]}))\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shut down flask server\n",
    "requests.post('http://127.0.0.1:5000/shutdown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geospatial data exercise\n",
    "The goal of this exercise is to read in some data from a shape file and visualize it on a map\n",
    "- The map should be dynamic. I want to zoom in and out to see more interesting aspects of the map\n",
    "- We want you to visualize the statistical sectors within a distance of 2KM of your home location.\n",
    "\n",
    "Specific steps to take:\n",
    "- Read in the shape file\n",
    "- Transform to WGS coordinates\n",
    "- Create a distance function (Haversine)\n",
    "- Create variables for home_lat, home_lon and perimeter_distance\n",
    "- Calculate centroid for each nis district\n",
    "- Calculate the distance to home for each nis district centroid \n",
    "- Figure out which nis districts are near your home\n",
    "- Create dynamic zoomable map\n",
    "- Visualize the nis districts near you (centroid <2km away), on the map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 1: Reading in the data\n",
    "local_path = 'data/external/shapefiles/'\n",
    "Path(local_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "url = 'https://statbel.fgov.be/sites/default/files/files/opendata/Statistische%20sectoren/sh_statbel_statistical_sectors_20200101.shp.zip'\n",
    "response = requests.get(url)\n",
    "file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "file.extractall(path=local_path)\n",
    "\n",
    "# renaming this from df for ease of reading\n",
    "gpd_stat_sectors = gpd.read_file(os.path.join(local_path,\n",
    "                                              'sh_statbel_statistical_sectors_20200101.shp'))\n",
    "# replaced deprecated init here\n",
    "gpd_stat_sectors = gpd_stat_sectors.to_crs(CRS('epsg:4326'))\n",
    "\n",
    "gpd_stat_sectors['centroid_lon'] = gpd_stat_sectors.centroid.x\n",
    "gpd_stat_sectors['centroid_lat'] = gpd_stat_sectors.centroid.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I assume that the statistical sectors are small enough to neglect curvature of the earth, so even with a geographic CRS the centroids are close enough to the real thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create some variables to indicate the location of your interest\n",
    "home_lat = 50.82449164657\n",
    "home_lon = 4.345775663707\n",
    "perimeter_distance = 2  # km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At some point we will need a distance function (google the Haversine formula, and implement it)\n",
    "def haversine(lat1: float,\n",
    "              lon1: float,\n",
    "              lat2: float,\n",
    "              lon2: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Haversine distance between points (lat1, lon1) and (lat2, lon2)\n",
    "    Parameters:\n",
    "    lat1: latifude of first point in decimal degrees\n",
    "    lon1: longitude of first point in decimal degrees\n",
    "    lat2: latitude of second point in decimal degrees\n",
    "    lon2: longitude of second point in decimal degrees\n",
    "    Returns:\n",
    "    distance in meters between the two points\n",
    "    \"\"\"\n",
    "\n",
    "    # convert degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    distance_lon = lon2 - lon1\n",
    "    distance_lat = lat2 - lat1\n",
    "    a = sin(distance_lat/2)**2 + cos(lat1)*cos(lat2)*sin(distance_lon/2)**2\n",
    "    c = 2*asin(sqrt(a))\n",
    "    radius = 6371  # earth radius in km\n",
    "\n",
    "    return c*radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, implement some sanity checks for your distance function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement sanity checks here\n",
    "tc_haversine = unittest.TestCase('__init__')\n",
    "\n",
    "# distance between same points is zero\n",
    "tc_haversine.assertEqual(haversine(1., 0., 1., 0.), 0.)\n",
    "tc_haversine.assertAlmostEqual(haversine(90., 0., -270., 0.), 0.)\n",
    "tc_haversine.assertAlmostEqual(haversine(90., 0., 450., 0.), 0)  # 450 = 90+360\n",
    "\n",
    "# distance between north and south poles is approx. 201015 km\n",
    "tc_haversine.assertAlmostEqual(haversine(90., 0., -90., 0.), 20015., places=0)\n",
    "\n",
    "# distance of flight from london to new york, data taken from\n",
    "# https://www.distance.to/London/New-York\n",
    "tc_haversine.assertAlmostEqual(haversine(51.500153, -0.126236, 40.714268, -74.005974),\n",
    "                               5570,\n",
    "                               places=0)\n",
    "\n",
    "# basic input vars type check\n",
    "with tc_haversine.assertRaises(TypeError) as context:\n",
    "    haversine('a', 2, 3, 4)\n",
    "tc_haversine.assertEqual(TypeError, type(context.exception))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a dynamical map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of the map goes here\n",
    "# calculate distance to home\n",
    "gpd_stat_sectors['distance_to_home'] = (gpd_stat_sectors[['centroid_lon', 'centroid_lat']]\n",
    "                                        .apply(lambda x: haversine(x['centroid_lat'],\n",
    "                                                                   x['centroid_lon'],\n",
    "                                                                   home_lat,\n",
    "                                                                   home_lon),\n",
    "                                        axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out places w. distance <2 km\n",
    "gpd_close_to_home = gpd_stat_sectors[gpd_stat_sectors['distance_to_home'] < perimeter_distance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init map\n",
    "coords_belgium = [50.5039, 4.4699]\n",
    "stat_sectors_map = folium.Map(location=coords_belgium, control_scale=True, zoom_start=8)\n",
    "\n",
    "# add neaby stat sectors\n",
    "gpd_close_to_home.apply(lambda x: folium.Circle(location=[x['centroid_lat'], x['centroid_lon']],\n",
    "                                                radius=10,\n",
    "                                                fill=True,\n",
    "                                                color='blue',\n",
    "                                                popup=x['T_SEC_NL'])\n",
    "                        .add_to(stat_sectors_map), axis=1)\n",
    "\n",
    "# add home point for reference\n",
    "folium.Circle(location=[home_lat, home_lon],\n",
    "              radius=10,\n",
    "              fill=True,\n",
    "              color='red',\n",
    "              popup='home').add_to(stat_sectors_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_sectors_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('coloryt-exercise')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "76f6f5d347fe3ee149b13079f8490726e24e784d56213079e08b5e11d1825189"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
